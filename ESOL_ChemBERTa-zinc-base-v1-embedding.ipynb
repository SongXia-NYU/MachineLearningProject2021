{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Homework 9:**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's import a few common modules, ensure MatplotLib plots figures inline and prepare a function to save the figures. We also check that Python 3.5 or later is installed (although Python 2.x may work, it is deprecated so we strongly recommend you use Python 3 instead), as well as Scikit-Learn ≥0.20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"HW9a\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rdkit\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "from rdkit import DataStructs\n",
    "from rdkit.DataStructs import ConvertToNumpyArray\n",
    "\n",
    "from rdkit.Chem import PandasTools\n",
    "import openchem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cano_smiles</th>\n",
       "      <th>activity</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cc1occc1C(=O)Nc1ccccc1</td>\n",
       "      <td>-3.30</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CC(C)=CCCC(C)=CC=O</td>\n",
       "      <td>-2.06</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c1ccc2c(c1)ccc1c2ccc2c3ccccc3ccc21</td>\n",
       "      <td>-7.87</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c1ccsc1</td>\n",
       "      <td>-1.33</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c1ccc2scnc2c1</td>\n",
       "      <td>-1.50</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          cano_smiles  activity  group\n",
       "0              Cc1occc1C(=O)Nc1ccccc1     -3.30  train\n",
       "1                  CC(C)=CCCC(C)=CC=O     -2.06  train\n",
       "2  c1ccc2c(c1)ccc1c2ccc2c3ccccc3ccc21     -7.87  train\n",
       "3                             c1ccsc1     -1.33  train\n",
       "4                       c1ccc2scnc2c1     -1.50  train"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "datapath = os.path.join(\".\", \"data/raw/esol.csv\")\n",
    "esol_data = pd.read_csv(datapath)\n",
    "esol_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1127.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-3.052010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.096392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-11.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-4.321000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-2.860000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-1.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.580000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          activity\n",
       "count  1127.000000\n",
       "mean     -3.052010\n",
       "std       2.096392\n",
       "min     -11.600000\n",
       "25%      -4.321000\n",
       "50%      -2.860000\n",
       "75%      -1.600000\n",
       "max       1.580000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "esol_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1127 entries, 0 to 1126\n",
      "Data columns (total 3 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   cano_smiles  1127 non-null   object \n",
      " 1   activity     1127 non-null   float64\n",
      " 2   group        1127 non-null   object \n",
      "dtypes: float64(1), object(2)\n",
      "memory usage: 26.5+ KB\n"
     ]
    }
   ],
   "source": [
    "#Generate data exploration\n",
    "esol_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ext3/miniconda3/lib/python3.7/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "851e6650334c4c4e8c152ccd41cbb47c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=501.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d45030b90fc40d7aac8c750ac31ae99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=9429.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "107ae92fe7404ef88fbb6ddafa6d3aa5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=3213.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd9e221583824a64b370b573c8cec92a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=150.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e887a8fac2d3431bab351de82c64ee3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=166.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f2d6e708b1347fbb2f44091eaa390a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=178812144.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "  \n",
    "tokenizer = AutoTokenizer.from_pretrained(\"seyonec/ChemBERTa-zinc-base-v1\")\n",
    "\n",
    "model = AutoModelForMaskedLM.from_pretrained(\"seyonec/ChemBERTa-zinc-base-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  0, 267,  21, 423,  21,  39, 263,  51,  13, 277,  21, 269,  21,   2,\n",
       "           1,   1,   1,   1,   1,   1,   1,   1,   1],\n",
       "        [  0, 262,  12,  39, 295, 285,  12,  39, 295, 262,  33,  51,   2,   1,\n",
       "           1,   1,   1,   1,   1,   1,   1,   1,   1],\n",
       "        [  0,  71,  21, 264,  22,  71,  12,  71,  21,  13, 264,  21,  71,  22,\n",
       "         264,  22,  71,  23, 269,  23, 264, 309,   2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(esol_data[\"cano_smiles\"][0:3].tolist(), return_tensors=\"pt\", padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s>'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.cls_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.cls_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "esol_data[\"embedding\"] = esol_data[\"cano_smiles\"].map(lambda smiles: model(**tokenizer(smiles, return_tensors=\"pt\",\n",
    "                                                                                       padding=True))[\"logits\"][0, 0, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = esol_data[esol_data[\"group\"]==\"train\"]\n",
    "data_valid = esol_data[esol_data[\"group\"]==\"valid\"]\n",
    "data_test = esol_data[esol_data[\"group\"]==\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "X_train = torch.stack(data_train[\"embedding\"].tolist()).detach().numpy()\n",
    "y_train = data_train[\"activity\"].values\n",
    "X_valid = torch.stack(data_valid[\"embedding\"].tolist()).detach().numpy()\n",
    "y_valid = data_valid[\"activity\"].values\n",
    "X_test = torch.stack(data_test[\"embedding\"].tolist()).detach().numpy()\n",
    "y_test = data_test[\"activity\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(901, 767)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "xgb = XGBRegressor(random_state=42)\n",
    "model = xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train RMSE  0.02894841276140909\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "y_train_pred = model.predict(X_train)\n",
    "xgb_mse = mean_squared_error(y_train, y_train_pred)\n",
    "xgb_rmse = np.sqrt(xgb_mse)\n",
    "print(\"train RMSE \", xgb_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4842408532879732"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_valid_pred = model.predict(X_valid)\n",
    "xgb_mse = mean_squared_error(y_valid, y_valid_pred)\n",
    "xgb_rmse = np.sqrt(xgb_mse)\n",
    "xgb_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3184776770404631"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred = model.predict(X_test)\n",
    "xgb_mse = mean_squared_error(y_test, y_test_pred)\n",
    "xgb_rmse = np.sqrt(xgb_mse)\n",
    "xgb_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1296/1296 [3:28:00<00:00,  9.63s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 0.1, 'gamma': 0.7, 'learning_rate': 0.1, 'max_depth': 7, 'min_child_weight': 9, 'n_estimators': 200, 'subsample': 0.7000000000000001}\n",
      "1.2566624365831074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'learning_rate': [0.001, 0.01, 0.1],\n",
    "    'gamma': [0.001, 0.01, 0.1, 0.7],\n",
    "    'min_child_weight': range(1, 10, 4),\n",
    "    'subsample': np.arange(0.1, 1.0, 0.3),\n",
    "    'colsample_bytree': np.arange(0.1, 1.0, 0.4),\n",
    "    'max_depth': range(3, 10, 4),\n",
    "    'n_estimators': range(200, 1000, 400)\n",
    "        }\n",
    "\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "grid = ParameterGrid(param_grid)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "best_model = None\n",
    "best_rmse=np.inf\n",
    "best_param = {}\n",
    "for this_param in tqdm(grid):\n",
    "    this_model = XGBRegressor(**this_param, random_state=42)\n",
    "    this_model.fit(X_train, y_train)\n",
    "#     print(this_model.predict(X_valid))\n",
    "    y_pred = this_model.predict(X_valid)\n",
    "    xgb_mse = mean_squared_error(y_valid, y_pred)\n",
    "    xgb_rmse = np.sqrt(xgb_mse)\n",
    "    if best_rmse > xgb_rmse:\n",
    "        best_model = this_model\n",
    "        best_rmse = xgb_rmse\n",
    "        best_param = this_param\n",
    "\n",
    "print(best_param)\n",
    "print(best_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "lin = RandomForestRegressor()\n",
    "lin.fit(X_train, y_train)\n",
    "model = lin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train RMSE  0.48464012001713086\n",
      "valid RMSE  1.4336586177157944\n",
      "test RMSE  1.21640373547409\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "y_train_pred = model.predict(X_train)\n",
    "xgb_mse = mean_squared_error(y_train, y_train_pred)\n",
    "xgb_rmse = np.sqrt(xgb_mse)\n",
    "print(\"train RMSE \", xgb_rmse)\n",
    "\n",
    "y_valid_pred = model.predict(X_valid)\n",
    "xgb_mse = mean_squared_error(y_valid, y_valid_pred)\n",
    "xgb_rmse = np.sqrt(xgb_mse)\n",
    "print(\"valid RMSE \", xgb_rmse)\n",
    "\n",
    "y_test_pred = model.predict(X_test)\n",
    "xgb_mse = mean_squared_error(y_test, y_test_pred)\n",
    "xgb_rmse = np.sqrt(xgb_mse)\n",
    "print(\"test RMSE \", xgb_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1080/1080 [3:53:19<00:00, 12.96s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 10, 'max_features': 0.8, 'min_impurity_decrease': 0, 'min_samples_leaf': 1, 'n_estimators': 200}\n",
      "1.4215655424302922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "        'n_estimators': [10, 50, 200, 500, 1000],  \n",
    "        'max_depth': range(3, 12),\n",
    "        'min_samples_leaf': [1, 3, 10, 50],\n",
    "        'min_impurity_decrease': [0, 0.01] ,\n",
    "        'max_features':  ['sqrt', 'log2', 0.8]\n",
    "        }\n",
    "\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "grid = ParameterGrid(param_grid)\n",
    "\n",
    "len(grid)\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "best_model = None\n",
    "best_rmse=np.inf\n",
    "best_param = {}\n",
    "for this_param in tqdm(grid):\n",
    "    this_model = RandomForestRegressor(**this_param, random_state=42)\n",
    "    this_model.fit(X_train, y_train)\n",
    "    forest_mse = mean_squared_error(y_valid, this_model.predict(X_valid))\n",
    "    forest_rmse = np.sqrt(forest_mse)\n",
    "    if best_rmse > forest_rmse:\n",
    "        best_model = this_model\n",
    "        best_rmse = forest_rmse\n",
    "        best_param = this_param\n",
    "        \n",
    "print(best_param)\n",
    "print(best_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "nn_dense = nn.Sequential(\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(767, 384),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(384, 190),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(190, 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: tensor(0.6487, grad_fn=<MseLossBackward>) valid loss: tensor(3.5886, dtype=torch.float64)\n",
      "train loss: tensor(3.3479, grad_fn=<MseLossBackward>) valid loss: tensor(3.6337, dtype=torch.float64)\n",
      "train loss: tensor(1.9942, grad_fn=<MseLossBackward>) valid loss: tensor(3.6187, dtype=torch.float64)\n",
      "train loss: tensor(1.5300, grad_fn=<MseLossBackward>) valid loss: tensor(3.2085, dtype=torch.float64)\n",
      "train loss: tensor(0.4254, grad_fn=<MseLossBackward>) valid loss: tensor(4.0099, dtype=torch.float64)\n",
      "train loss: tensor(1.5355, grad_fn=<MseLossBackward>) valid loss: tensor(3.0528, dtype=torch.float64)\n",
      "train loss: tensor(0.3423, grad_fn=<MseLossBackward>) valid loss: tensor(3.1474, dtype=torch.float64)\n",
      "train loss: tensor(0.9480, grad_fn=<MseLossBackward>) valid loss: tensor(3.1459, dtype=torch.float64)\n",
      "train loss: tensor(0.4106, grad_fn=<MseLossBackward>) valid loss: tensor(3.1181, dtype=torch.float64)\n",
      "train loss: tensor(0.7483, grad_fn=<MseLossBackward>) valid loss: tensor(3.0599, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "reg_model = nn_dense\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(reg_model.parameters(), lr=1e-3)\n",
    "n_epoches = 10\n",
    "# data_train.shape[0]\n",
    "index_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(torch.arange(100))\n",
    "                                           , batch_size=8, shuffle=True)\n",
    "for i in range(n_epoches):\n",
    "    for train_idx in (index_loader):\n",
    "        optimizer.zero_grad()\n",
    "        train_idx = train_idx[0].tolist()\n",
    "        pred = reg_model(torch.as_tensor(X_train[train_idx]))\n",
    "        label = torch.as_tensor(data_train[\"activity\"][train_idx].values).float()\n",
    "        loss = loss_fn(pred.reshape(-1), label.reshape(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    val_loss = 999\n",
    "    with torch.no_grad():\n",
    "        pred = reg_model(torch.as_tensor(X_valid))\n",
    "        label = torch.as_tensor(data_valid[\"activity\"].values)\n",
    "        val_loss = loss_fn(pred.reshape(-1), label.reshape(-1))\n",
    "    print(\"train loss:\", loss, \"valid loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "nav_menu": {
   "height": "279px",
   "width": "309px"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
